# moneyworld_scraper.py
# 1æœ¬ã§ã€Œå…¨ä»¶å–å¾—(all) / æœªå–å¾—ã®ã¿(missing)ã€ã«å¯¾å¿œã™ã‚‹ Playwright ç‰ˆ
# - æœªæŒ‡å®šæ™‚ã¯ consensus_url ã®æœ€æ–° target_date ã‚’è‡ªå‹•æ¡ç”¨
# - ç¤¼å„€æœ€å„ªå…ˆ: QPSåˆ¶å¾¡ãƒ»ä¸¦åˆ—ä¸Šé™ãƒ»ç”»åƒ/ãƒ•ã‚©ãƒ³ãƒˆé®æ–­ãƒ»å …ç‰¢å¾…æ©Ÿãƒ»æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
# - é«˜é€ŸåŒ–: WAL + ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆ (--batch)
# - liquidity ã¯ dd/span[3] ã«ä¿®æ­£æ¸ˆã¿

import asyncio
import datetime
import sqlite3
import time
import os
import argparse
from typing import Dict, Any, List, Tuple, Iterable, Optional
from contextlib import asynccontextmanager

from playwright.async_api import async_playwright, TimeoutError as PwTimeout

DB_PATH = "/market_data.db"

# ====== ãƒãƒ©ã‚¤ãƒˆè¨­å®šï¼ˆã‚µã‚¤ãƒˆè² è·å„ªå…ˆï¼‰======
DEFAULT_MAX_CONCURRENCY = 4   # 4ã€œ6æ¨å¥¨
DEFAULT_TARGET_QPS = 0.7      # å…¨ä½“QPSä¸Šé™ï¼ˆ0.6ã€œ0.9æ¨å¥¨ï¼‰
DEFAULT_BATCH_COMMIT = 100    # DBã‚³ãƒŸãƒƒãƒˆé–“éš”
NAV_TIMEOUT_MS = 25000        # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³/å¾…æ©Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
RETRIES = 3                   # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

# å¿…é ˆã‚»ãƒ¬ã‚¯ã‚¿ï¼ˆãƒ¬ãƒ³ãƒ€å®Œäº†ç›®å®‰ï¼‰
SEL_STOCK_PAGE = "#stock-page"
SEL_READY = 'xpath=//*[@id="sec3_quick_stock_info_0"]/div[2]/div/div/dl[1]/dd/span[3]'

# å–å¾—XPathsï¼ˆliquidity ã¯ dd/span[3]ï¼‰
XPATHS: Dict[str, str] = {
    "rating":      'string(//*[@id="stock-page"]/div[1]/div[3]/div[1]/section/div[1]/div[2]/div[3]/div[1]/span)',
    "sales":       'string(//*[@id="stock-page"]/div[1]/div[3]/div[1]/section/div[1]/div[2]/div[3]/div[2]/div[2]/div[1]/span)',
    "profit":      'string(//*[@id="stock-page"]/div[1]/div[3]/div[1]/section/div[1]/div[2]/div[3]/div[2]/div[2]/div[2]/span)',
    "scale":       'string(//*[@id="sec3_quick_stock_info_0"]/div[2]/div/div/dl[1]/dd/span[3])',
    "cheap":       'string(//*[@id="sec3_quick_stock_info_0"]/div[2]/div/div/dl[2]/dd/span[3])',
    "growth":      'string(//*[@id="sec3_quick_stock_info_0"]/div[2]/div/div/dl[3]/dd/span[3])',
    "profitab":    'string(//*[@id="sec3_quick_stock_info_0"]/div[2]/div/div/dl[4]/dd/span[3])',
    "safety":      'string(//*[@id="sec3_quick_stock_info_0"]/div[2]/div/div/dl[5]/dd/span[3])',
    "risk":        'string(//*[@id="sec3_quick_stock_info_0"]/div[3]/div/div/dl[1]/dd/span[3])',
    "return_rate": 'string(//*[@id="sec3_quick_stock_info_0"]/div[3]/div/div/dl[2]/dd/span[3])',
    "liquidity":   'string(//*[@id="sec3_quick_stock_info_0"]/div[3]/div/div/dl[3]/dd/span[3])',
    "trend":       'string(//*[@id="sec3_quick_stock_info_0"]/div[3]/div/div/dl[4]/dd/span[3])',
    "forex":       'string(//*[@id="sec3_quick_stock_info_0"]/div[3]/div/div/dl[5]/dd/span[3])',
    "technical":   'string(//*[@id="sec3_quick_stock_info_0"]/div[3]/div/div/dl[6]/dd/span[3])',
}

def _pct(s: str) -> str:
    s = (s or "").strip()
    if s and not s.endswith("%"):
        return s + "%"
    return s or ""

class TokenBucket:
    """å˜ä¸€ãƒ—ãƒ­ã‚»ã‚¹å†…ã®ç°¡æ˜“ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆã§å…¨ä½“QPSã‚’åˆ¶å¾¡"""
    def __init__(self, qps: float):
        self.interval = 1.0 / max(qps, 0.0001)
        self._lock = asyncio.Lock()
        self._next_time = time.monotonic()

    async def acquire(self):
        async with self._lock:
            now = time.monotonic()
            if now < self._next_time:
                await asyncio.sleep(self._next_time - now)
            self._next_time = max(now, self._next_time) + self.interval

@asynccontextmanager
async def browser_context(play, headless=True):
    browser = await play.chromium.launch(
        headless=headless,
        args=["--disable-gpu", "--disable-dev-shm-usage", "--no-sandbox"]
    )
    context = await browser.new_context(
        user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome Safari",
        java_script_enabled=True,
        bypass_csp=True,
        viewport={"width": 1366, "height": 768}
    )
    # è»½é‡åŒ–: ç”»åƒ/ãƒ•ã‚©ãƒ³ãƒˆ/ãƒ¡ãƒ‡ã‚£ã‚¢é®æ–­ï¼ˆCSSã¨XHRã¯è¨±å¯ï¼‰
    async def route_handler(route, request):
        if request.resource_type in ("image", "media", "font"):
            await route.abort()
        else:
            await route.continue_()
    await context.route("**/*", route_handler)
    try:
        yield context
    finally:
        await context.close()
        await browser.close()

async def fetch_one(page, code: str, url: str) -> Tuple[str, Dict[str, Any]]:
    await page.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT_MS)
    await page.wait_for_selector(SEL_STOCK_PAGE, timeout=NAV_TIMEOUT_MS)
    await page.wait_for_selector(SEL_READY, timeout=NAV_TIMEOUT_MS)
    data = await page.evaluate(
        """(xps) => {
            const evalStr = (xp) => {
              try { return document.evaluate(xp, document, null, XPathResult.STRING_TYPE, null).stringValue.trim(); }
              catch(e){ return ""; }
            };
            const out = {};
            for (const [k, xp] of Object.entries(xps)) out[k] = evalStr(xp);
            return out;
        }""",
        XPATHS
    )
    data["sales"]  = _pct(data.get("sales", ""))
    data["profit"] = _pct(data.get("profit", ""))
    return code, data

async def worker(name: int,
                 ctx,
                 jobs: asyncio.Queue,
                 bucket: TokenBucket,
                 results: asyncio.Queue):
    page = await ctx.new_page()
    try:
        while True:
            item = await jobs.get()
            if item is None:
                break
            code, url = item
            await bucket.acquire()  # å…¨ä½“QPSåˆ¶å¾¡
            delay = 0.8
            last_err = None
            for attempt in range(RETRIES):
                try:
                    c, data = await fetch_one(page, code, url)
                    await results.put((c, data, None))
                    break
                except (PwTimeout, Exception) as e:
                    last_err = e
                    if attempt < RETRIES - 1:
                        await asyncio.sleep(delay)
                        delay *= 1.8
                    else:
                        await results.put((code, None, last_err))
            jobs.task_done()
    finally:
        await page.close()

def ensure_tables(conn: sqlite3.Connection):
    cur = conn.cursor()
    # æ›¸ãè¾¼ã¿é«˜é€ŸåŒ–ï¼ˆWALï¼‹synchronous=NORMALï¼‰
    cur.execute("PRAGMA journal_mode=WAL;")
    cur.execute("PRAGMA synchronous=NORMAL;")
    conn.commit()
    # moneyworld_reports
    cur.execute("""
        CREATE TABLE IF NOT EXISTS moneyworld_reports (
            target_date TEXT,
            code TEXT,
            rating TEXT,
            sales TEXT,
            profit TEXT,
            scale TEXT,
            cheap TEXT,
            growth TEXT,
            profitab TEXT,
            safety TEXT,
            risk TEXT,
            return_rate TEXT,
            liquidity TEXT,
            trend TEXT,
            forex TEXT,
            technical TEXT,
            PRIMARY KEY (target_date, code)
        )
    """)
    conn.commit()

def resolve_target_date(conn: sqlite3.Connection, explicit: Optional[str]) -> Optional[str]:
    """æ˜ç¤ºãŒç„¡ã‘ã‚Œã° consensus_url ã®æœ€æ–°æ—¥ä»˜ã‚’æ¡ç”¨"""
    if explicit:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
        datetime.datetime.strptime(explicit, "%Y%m%d")
        return explicit
    cur = conn.cursor()
    cur.execute("SELECT MAX(target_date) FROM consensus_url")
    row = cur.fetchone()
    td = row[0] if row else None
    if td:
        try:
            datetime.datetime.strptime(td, "%Y%m%d")
            return td
        except Exception:
            return None
    return None

def load_targets(conn: sqlite3.Connection, target_date: str, mode: str) -> List[Tuple[str,str]]:
    cur = conn.cursor()
    if mode == "all":
        cur.execute("""
            SELECT code, quickurl
            FROM consensus_url
            WHERE target_date = ?
        """, (target_date,))
        rows = [(c, u) for c, u in cur.fetchall() if u]
        return rows

    # mode == "missing": nikkei_reports ã‚’æ¯é›†åˆã«ã—ã¦ moneyworld_reports æœªä¿å­˜ã‚’æŠ½å‡º
    cur.execute("""
        SELECT code FROM nikkei_reports WHERE target_date = ?
        EXCEPT
        SELECT code FROM moneyworld_reports WHERE target_date = ?
    """, (target_date, target_date))
    codes = [r[0] for r in cur.fetchall()]
    if not codes:
        return []
    placeholders = ",".join(["?"] * len(codes))
    cur.execute(f"""
        SELECT code, quickurl FROM consensus_url
        WHERE target_date = ? AND code IN ({placeholders})
    """, [target_date] + codes)
    return [(c, u) for c, u in cur.fetchall() if u]

async def main():
    p = argparse.ArgumentParser()
    p.add_argument("-a", "--target_date", help="YYYYMMDDï¼ˆæœªæŒ‡å®šãªã‚‰ consensus_url ã®æœ€æ–°æ—¥ä»˜ï¼‰")
    p.add_argument("--mode", choices=["missing", "all"], default="missing",
                   help="missing: nikkeiåŸºæº–ã§æœªå–å¾—ã®ã¿ / all: consensus_urlå…¨ä»¶")
    p.add_argument("--concurrency", type=int, default=DEFAULT_MAX_CONCURRENCY, help="åŒæ™‚ã‚¿ãƒ–æ•°ï¼ˆ4ã€œ6æ¨å¥¨ï¼‰")
    p.add_argument("--qps", type=float, default=DEFAULT_TARGET_QPS, help="å…¨ä½“QPSä¸Šé™ï¼ˆ0.6ã€œ0.9æ¨å¥¨ï¼‰")
    p.add_argument("--batch", type=int, default=DEFAULT_BATCH_COMMIT, help="DBã‚³ãƒŸãƒƒãƒˆé–“éš”")
    p.add_argument("--headful", action="store_true", help="ãƒ˜ãƒƒãƒ‰ãƒ•ãƒ«ã§èµ·å‹•ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
    args = p.parse_args()

    # DB æº–å‚™
    conn = sqlite3.connect(DB_PATH)
    ensure_tables(conn)
    cur = conn.cursor()

    # å¯¾è±¡æ—¥ä»˜ã®æ±ºå®š
    target_date = resolve_target_date(conn, args.target_date)
    if not target_date:
        print("âŒ target_date ã‚’æ±ºå®šã§ãã¾ã›ã‚“ï¼ˆ-a YYYYMMDD ã‚’æŒ‡å®šã™ã‚‹ã‹ã€consensus_url ã«ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼‰")
        conn.close()
        return
    print(f"â–¶ target_date = {target_date} / mode = {args.mode}")

    # å¯¾è±¡URLã®ãƒ­ãƒ¼ãƒ‰
    targets = load_targets(conn, target_date, args.mode)
    if not targets:
        if args.mode == "missing":
            print(f"âœ… {target_date} æœªå–å¾—ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆmode=missingï¼‰")
        else:
            print(f"âš ï¸ {target_date} å¯¾è±¡URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆmode=allï¼‰")
        conn.close()
        return

    # ã‚­ãƒ¥ãƒ¼
    jobs: asyncio.Queue = asyncio.Queue()
    results: asyncio.Queue = asyncio.Queue()
    for item in targets:
        await jobs.put(item)
    total = len(targets)

    bucket = TokenBucket(args.qps)
    done = 0
    ok = 0
    ng = 0
    buf: List[Tuple] = []

    async with async_playwright() as play:
        async with browser_context(play, headless=not args.headful) as ctx:
            workers = [
                asyncio.create_task(worker(i+1, ctx, jobs, bucket, results))
                for i in range(max(1, min(args.concurrency, 12)))
            ]

            async def stop_workers():
                for _ in workers:
                    await jobs.put(None)

            try:
                while done < total:
                    code, data, err = await results.get()
                    done += 1
                    if err is None and data:
                        row = (
                            target_date, code,
                            data.get("rating",""), data.get("sales",""), data.get("profit",""),
                            data.get("scale",""), data.get("cheap",""), data.get("growth",""), data.get("profitab",""),
                            data.get("safety",""), data.get("risk",""), data.get("return_rate",""), data.get("liquidity",""),
                            data.get("trend",""), data.get("forex",""), data.get("technical","")
                        )
                        buf.append(row)
                        ok += 1
                        if len(buf) >= args.batch:
                            cur.executemany("""
                                INSERT OR REPLACE INTO moneyworld_reports (
                                    target_date, code, rating, sales, profit, scale, cheap, growth, profitab,
                                    safety, risk, return_rate, liquidity, trend, forex, technical
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, buf)
                            conn.commit()
                            buf.clear()
                        if done % 50 == 0 or done == total:
                            print(f"âœ… {done}/{total} / OK:{ok} NG:{ng}")
                    else:
                        ng += 1
                        print(f"âŒ {done}/{total} code:{code} err:{repr(err)[:120]}")
            finally:
                if buf:
                    cur.executemany("""
                        INSERT OR REPLACE INTO moneyworld_reports (
                            target_date, code, rating, sales, profit, scale, cheap, growth, profitab,
                            safety, risk, return_rate, liquidity, trend, forex, technical
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, buf)
                    conn.commit()
                await stop_workers()
                await asyncio.gather(*workers, return_exceptions=True)
                conn.close()
                print(f"ğŸ å®Œäº† / OK:{ok} NG:{ng} / å¯¾è±¡:{total} / mode={args.mode} / date={target_date}")

if __name__ == "__main__":
    asyncio.run(main())
